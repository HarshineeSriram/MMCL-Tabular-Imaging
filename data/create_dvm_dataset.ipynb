{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torchvision.io import read_image\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_columns = 700\n",
    "\n",
    "BASE = ''\n",
    "TABLES = join(BASE, 'tables_V2.0')\n",
    "FEATURES = join(BASE, 'features')\n",
    "\n",
    "front_view_only = False\n",
    "\n",
    "from typing import List\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import k_means, SpectralClustering\n",
    "import multiprocessing as mp\n",
    "\n",
    "ANALYSIS = join(BASE, 'analysis')\n",
    "\n",
    "def conf_matrix_from_matrices(mat_gt, mat_pred):\n",
    "  overlap_and = (mat_pred & mat_gt)\n",
    "  tp = overlap_and.sum()\n",
    "  fp = mat_pred.sum()-overlap_and.sum()\n",
    "  fn = mat_gt.sum()-overlap_and.sum()\n",
    "  tn = mat_gt.shape[0]**2-(tp+fp+fn)\n",
    "  return tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_or_save(obj, path, index=None, header=None):\n",
    "  if isinstance(obj, pd.DataFrame):\n",
    "    if index is None or header is None:\n",
    "      raise ValueError('Index and header must be specified for saving a dataframe')\n",
    "    if os.path.exists(path):\n",
    "      if not header:\n",
    "        saved_df = pd.read_csv(path,header=None)\n",
    "      else:\n",
    "        saved_df = pd.read_csv(path)\n",
    "      naked_df = saved_df.reset_index(drop=True)\n",
    "      naked_df.columns = range(naked_df.shape[1])\n",
    "      naked_obj = obj.reset_index(drop=not index)\n",
    "      naked_obj.columns = range(naked_obj.shape[1])\n",
    "      if naked_df.round(6).equals(naked_obj.round(6)):\n",
    "        return\n",
    "      else:\n",
    "        diff = (naked_df.round(6) == naked_obj.round(6))\n",
    "        diff[naked_df.isnull()] = naked_df.isnull() & naked_obj.isnull()\n",
    "        assert diff.all().all(), \"Dataframe is not the same as saved dataframe\"\n",
    "    else:\n",
    "      obj.to_csv(path, index=index, header=header)\n",
    "  else:\n",
    "    if os.path.exists(path):\n",
    "      saved_obj = torch.load(path)\n",
    "      if isinstance(obj, list):\n",
    "        for i in range(len(obj)):\n",
    "          check_array_equality(obj[i], saved_obj[i])\n",
    "      else:\n",
    "        check_array_equality(obj, saved_obj)\n",
    "    else:\n",
    "      print(f'Saving to {path}')\n",
    "      torch.save(obj, path)\n",
    "\n",
    "\n",
    "def check_array_equality(ob1, ob2):\n",
    "  if torch.is_tensor(ob1) or isinstance(ob1, np.ndarray):\n",
    "    assert (ob2 == ob1).all()\n",
    "  else:\n",
    "    assert ob2 == ob1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tabular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_48952\\622457649.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ad_data = pd.read_csv(join(TABLES, 'Ad_table.csv'))\n"
     ]
    }
   ],
   "source": [
    "ad_data = pd.read_csv(join(TABLES, 'Ad_table.csv'))\n",
    "ad_data.rename(columns={' Genmodel': 'Genmodel', ' Genmodel_ID': 'Genmodel_ID'}, inplace=True)\n",
    "\n",
    "basic_data = pd.read_csv(join(TABLES, 'Basic_table.csv'))\n",
    "\n",
    "image_data = pd.read_csv(join(TABLES, 'Image_table.csv'))\n",
    "image_data.rename(columns={' Image_ID': 'Image_ID', ' Image_name': 'Image_name', ' Predicted_viewpoint':'Predicted_viewpoint', ' Quality_check':'Quality_check'}, inplace=True)\n",
    "\n",
    "price_data = pd.read_csv(join(TABLES, 'Price_table.csv'))\n",
    "price_data.rename(columns={' Genmodel': 'Genmodel', ' Genmodel_ID': 'Genmodel_ID', ' Year': 'Year', ' Entry_price': 'Entry_price'}, inplace=True)\n",
    "\n",
    "sales_data = pd.read_csv(join(TABLES, 'Sales_table.csv'))\n",
    "sales_data.rename(columns={'Genmodel ': 'Genmodel', 'Genmodel_ID ': 'Genmodel_ID'}, inplace=True)\n",
    "\n",
    "trim_data = pd.read_csv(join(TABLES, 'Trim_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "      <th>Quality_check</th>\n",
       "      <th>Adv_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$1$$1</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$1$$image_...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$10$$11</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$10$$image...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$4$$0</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$4$$image_...</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>2_1$$4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$8$$3</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Blue$$2_1$$8$$image_...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_1$$8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1$$13$$8</td>\n",
       "      <td>Abarth$$124 Spider$$2017$$Grey$$2_1$$13$$image...</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>2_1$$13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451766</th>\n",
       "      <td>96_18</td>\n",
       "      <td>96_18$$919$$3</td>\n",
       "      <td>Volvo$$XC90$$2019$$White$$96_18$$919$$image_3.jpg</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96_18$$919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451771</th>\n",
       "      <td>97_1</td>\n",
       "      <td>97_1$$1$$1</td>\n",
       "      <td>Westfield$$Sport$$2006$$Yellow$$97_1$$1$$image...</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97_1$$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451772</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$2$$14</td>\n",
       "      <td>Zenos$$E10$$2016$$Green$$99_1$$2$$image_14.jpg</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99_1$$2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451775</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$3$$1</td>\n",
       "      <td>Zenos$$E10$$2016$$Grey$$99_1$$3$$image_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>99_1$$3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451780</th>\n",
       "      <td>99_1</td>\n",
       "      <td>99_1$$1$$0</td>\n",
       "      <td>Zenos$$E10$$2016$$Red$$99_1$$1$$image_0.jpg</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99_1$$1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247236 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Genmodel_ID       Image_ID  \\\n",
       "0               2_1      2_1$$1$$1   \n",
       "1               2_1    2_1$$10$$11   \n",
       "8               2_1      2_1$$4$$0   \n",
       "14              2_1      2_1$$8$$3   \n",
       "18              2_1     2_1$$13$$8   \n",
       "...             ...            ...   \n",
       "1451766       96_18  96_18$$919$$3   \n",
       "1451771        97_1     97_1$$1$$1   \n",
       "1451772        99_1    99_1$$2$$14   \n",
       "1451775        99_1     99_1$$3$$1   \n",
       "1451780        99_1     99_1$$1$$0   \n",
       "\n",
       "                                                Image_name  \\\n",
       "0        Abarth$$124 Spider$$2017$$Blue$$2_1$$1$$image_...   \n",
       "1        Abarth$$124 Spider$$2017$$Blue$$2_1$$10$$image...   \n",
       "8        Abarth$$124 Spider$$2017$$Blue$$2_1$$4$$image_...   \n",
       "14       Abarth$$124 Spider$$2017$$Blue$$2_1$$8$$image_...   \n",
       "18       Abarth$$124 Spider$$2017$$Grey$$2_1$$13$$image...   \n",
       "...                                                    ...   \n",
       "1451766  Volvo$$XC90$$2019$$White$$96_18$$919$$image_3.jpg   \n",
       "1451771  Westfield$$Sport$$2006$$Yellow$$97_1$$1$$image...   \n",
       "1451772     Zenos$$E10$$2016$$Green$$99_1$$2$$image_14.jpg   \n",
       "1451775       Zenos$$E10$$2016$$Grey$$99_1$$3$$image_1.jpg   \n",
       "1451780        Zenos$$E10$$2016$$Red$$99_1$$1$$image_0.jpg   \n",
       "\n",
       "         Predicted_viewpoint Quality_check      Adv_ID  \n",
       "0                         45           NaN      2_1$$1  \n",
       "1                         45           NaN     2_1$$10  \n",
       "8                          0             P      2_1$$4  \n",
       "14                         0           NaN      2_1$$8  \n",
       "18                         0             P     2_1$$13  \n",
       "...                      ...           ...         ...  \n",
       "1451766                  225           NaN  96_18$$919  \n",
       "1451771                   45           NaN     97_1$$1  \n",
       "1451772                  180           NaN     99_1$$2  \n",
       "1451775                    0             P     99_1$$3  \n",
       "1451780                  225           NaN     99_1$$1  \n",
       "\n",
       "[247236 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parser_adv_id(x):\n",
    "  split = x[\"Image_ID\"].split('$$')\n",
    "  return f\"{split[0]}$${split[1]}\"\n",
    "\n",
    "image_data[\"Adv_ID\"] = image_data.apply(lambda x: parser_adv_id(x), axis=1)\n",
    "if front_view_only:\n",
    "  image_data = image_data[(image_data[\"Quality_check\"]==\"P\")&(image_data[\"Predicted_viewpoint\"]==0)]\n",
    "image_data.drop_duplicates(subset=['Adv_ID'], inplace=True)\n",
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268255\n",
      "224724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Engin_size</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>60000</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$13</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>53444</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$15</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Black</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>61500</td>\n",
       "      <td>6.7L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>16500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$16</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>49700</td>\n",
       "      <td>4.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>29500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>75000</td>\n",
       "      <td>6.8L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224719</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>100390</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224720</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>149000</td>\n",
       "      <td>2.0L</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224721</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>98167</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224722</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>152230</td>\n",
       "      <td>1.8L</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1495</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224723</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>111000</td>\n",
       "      <td>2.4L</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224724 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Maker Genmodel Genmodel_ID     Adv_ID  Adv_year  Adv_month   Color  \\\n",
       "0       Bentley   Arnage        10_1    10_1$$1      2018          4  Silver   \n",
       "1       Bentley   Arnage        10_1   10_1$$13      2018          4  Silver   \n",
       "2       Bentley   Arnage        10_1   10_1$$15      2018          4   Black   \n",
       "3       Bentley   Arnage        10_1   10_1$$16      2017         12    Blue   \n",
       "4       Bentley   Arnage        10_1   10_1$$18      2018          4   White   \n",
       "...         ...      ...         ...        ...       ...        ...     ...   \n",
       "224719    Volvo      V50        96_9  96_9$$353      2018          5  Silver   \n",
       "224720    Volvo      V50        96_9  96_9$$374      2018          5  Silver   \n",
       "224721    Volvo      V50        96_9  96_9$$457      2018          5    Grey   \n",
       "224722    Volvo      V50        96_9  96_9$$477      2018          2    Grey   \n",
       "224723    Volvo      V50        96_9  96_9$$525      2018          5  Silver   \n",
       "\n",
       "        Reg_year Bodytype Runned_Miles Engin_size    Gearbox Fuel_type  Price  \\\n",
       "0         2000.0   Saloon        60000       6.8L  Automatic    Petrol  21500   \n",
       "1         2000.0   Saloon        53444       6.8L  Automatic    Petrol  21995   \n",
       "2         2000.0   Saloon        61500       6.7L  Automatic    Petrol  16500   \n",
       "3         2000.0   Saloon        49700       4.4L  Automatic    Petrol  29500   \n",
       "4         2000.0   Saloon        75000       6.8L  Automatic    Petrol  17995   \n",
       "...          ...      ...          ...        ...        ...       ...    ...   \n",
       "224719    2004.0   Estate       100390       2.4L  Automatic    Petrol   1999   \n",
       "224720    2004.0   Estate       149000       2.0L     Manual    Diesel   1450   \n",
       "224721    2004.0   Estate        98167       2.4L  Automatic    Petrol   3995   \n",
       "224722    2004.0   Estate       152230       1.8L     Manual    Petrol   1495   \n",
       "224723    2004.0   Estate       111000       2.4L  Automatic    Petrol   2895   \n",
       "\n",
       "        Seat_num  Door_num  Entry_price  Year  \n",
       "0            5.0       4.0       145000  2000  \n",
       "1            5.0       4.0       145000  2000  \n",
       "2            NaN       NaN       145000  2000  \n",
       "3            5.0       4.0       145000  2000  \n",
       "4            5.0       4.0       145000  2000  \n",
       "...          ...       ...          ...   ...  \n",
       "224719       5.0       5.0        17165  2004  \n",
       "224720       5.0       5.0        17165  2004  \n",
       "224721       5.0       5.0        17165  2004  \n",
       "224722       5.0       5.0        17165  2004  \n",
       "224723       5.0       5.0        17165  2004  \n",
       "\n",
       "[224724 rows x 18 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ad_data))\n",
    "feature_df = ad_data.merge(price_data[['Genmodel_ID', 'Entry_price', 'Year']], left_on=['Genmodel_ID','Reg_year'], right_on=['Genmodel_ID','Year'])\n",
    "print(len(feature_df))\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = feature_df.merge(image_data[['Adv_ID', 'Image_name', 'Predicted_viewpoint']], left_on=['Adv_ID'], right_on=['Adv_ID'])\n",
    "assert data_df[\"Adv_ID\"].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "      <th>Engine_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>60000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$1$$image_...</td>\n",
       "      <td>45</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$13</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>53444</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>21995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$13$$image...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$16</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>49700</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>29500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Blue$$10_1$$16$$image_1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$18</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>75000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$White$$10_1$$18$$image_...</td>\n",
       "      <td>90</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$26</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>98000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>17945</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Bentley$$Arnage$$2000$$Silver$$10_1$$26$$image...</td>\n",
       "      <td>225</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209030</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>100390</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209031</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>149000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209032</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>98167</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3995</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209033</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>152230</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1495</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg</td>\n",
       "      <td>315</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209034</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>V50</td>\n",
       "      <td>96_9</td>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Estate</td>\n",
       "      <td>111000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>2895</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17165</td>\n",
       "      <td>2004</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg</td>\n",
       "      <td>135</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184562 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Maker Genmodel Genmodel_ID     Adv_ID  Adv_year  Adv_month   Color  \\\n",
       "0       Bentley   Arnage        10_1    10_1$$1      2018          4  Silver   \n",
       "1       Bentley   Arnage        10_1   10_1$$13      2018          4  Silver   \n",
       "3       Bentley   Arnage        10_1   10_1$$16      2017         12    Blue   \n",
       "4       Bentley   Arnage        10_1   10_1$$18      2018          4   White   \n",
       "5       Bentley   Arnage        10_1   10_1$$26      2017          5  Silver   \n",
       "...         ...      ...         ...        ...       ...        ...     ...   \n",
       "209030    Volvo      V50        96_9  96_9$$353      2018          5  Silver   \n",
       "209031    Volvo      V50        96_9  96_9$$374      2018          5  Silver   \n",
       "209032    Volvo      V50        96_9  96_9$$457      2018          5    Grey   \n",
       "209033    Volvo      V50        96_9  96_9$$477      2018          2    Grey   \n",
       "209034    Volvo      V50        96_9  96_9$$525      2018          5  Silver   \n",
       "\n",
       "        Reg_year Bodytype Runned_Miles    Gearbox Fuel_type  Price  Seat_num  \\\n",
       "0         2000.0   Saloon        60000  Automatic    Petrol  21500       5.0   \n",
       "1         2000.0   Saloon        53444  Automatic    Petrol  21995       5.0   \n",
       "3         2000.0   Saloon        49700  Automatic    Petrol  29500       5.0   \n",
       "4         2000.0   Saloon        75000  Automatic    Petrol  17995       5.0   \n",
       "5         2000.0   Saloon        98000  Automatic    Petrol  17945       5.0   \n",
       "...          ...      ...          ...        ...       ...    ...       ...   \n",
       "209030    2004.0   Estate       100390  Automatic    Petrol   1999       5.0   \n",
       "209031    2004.0   Estate       149000     Manual    Diesel   1450       5.0   \n",
       "209032    2004.0   Estate        98167  Automatic    Petrol   3995       5.0   \n",
       "209033    2004.0   Estate       152230     Manual    Petrol   1495       5.0   \n",
       "209034    2004.0   Estate       111000  Automatic    Petrol   2895       5.0   \n",
       "\n",
       "        Door_num  Entry_price  Year  \\\n",
       "0            4.0       145000  2000   \n",
       "1            4.0       145000  2000   \n",
       "3            4.0       145000  2000   \n",
       "4            4.0       145000  2000   \n",
       "5            4.0       145000  2000   \n",
       "...          ...          ...   ...   \n",
       "209030       5.0        17165  2004   \n",
       "209031       5.0        17165  2004   \n",
       "209032       5.0        17165  2004   \n",
       "209033       5.0        17165  2004   \n",
       "209034       5.0        17165  2004   \n",
       "\n",
       "                                               Image_name  \\\n",
       "0       Bentley$$Arnage$$2000$$Silver$$10_1$$1$$image_...   \n",
       "1       Bentley$$Arnage$$2000$$Silver$$10_1$$13$$image...   \n",
       "3       Bentley$$Arnage$$2000$$Blue$$10_1$$16$$image_1...   \n",
       "4       Bentley$$Arnage$$2000$$White$$10_1$$18$$image_...   \n",
       "5       Bentley$$Arnage$$2000$$Silver$$10_1$$26$$image...   \n",
       "...                                                   ...   \n",
       "209030   Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg   \n",
       "209031   Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg   \n",
       "209032     Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg   \n",
       "209033     Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg   \n",
       "209034   Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg   \n",
       "\n",
       "        Predicted_viewpoint  Engine_size  \n",
       "0                        45          6.8  \n",
       "1                         0          6.8  \n",
       "3                         0          4.4  \n",
       "4                        90          6.8  \n",
       "5                       225          6.8  \n",
       "...                     ...          ...  \n",
       "209030                   45          2.4  \n",
       "209031                    0          2.0  \n",
       "209032                   45          2.4  \n",
       "209033                  315          1.8  \n",
       "209034                  135          2.4  \n",
       "\n",
       "[184562 rows x 20 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_engine_size(x):\n",
    "  return float(x['Engin_size'][:-1])\n",
    "\n",
    "data_df.dropna(inplace=True)\n",
    "data_df['Engine_size'] = data_df.apply(lambda x: extract_engine_size(x), axis=1)\n",
    "data_df.drop(columns=['Engin_size'], inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = data_df.loc[:,'Adv_ID']\n",
    "image_name_df = data_df.loc[:,'Image_name']\n",
    "viewpoint_df = data_df.loc[:,'Predicted_viewpoint']\n",
    "\n",
    "continuous_df = data_df.loc[:,(\n",
    "  'Adv_year',\n",
    "  'Adv_month',\n",
    "  'Reg_year',\n",
    "  'Runned_Miles',\n",
    "  'Price',\n",
    "  'Seat_num',\n",
    "  'Door_num',\n",
    "  'Entry_price', \n",
    "  'Engine_size'\n",
    "  )]\n",
    "\n",
    "categorical_ids = ['Color',\n",
    "  'Bodytype',\n",
    "  'Gearbox',\n",
    "  'Fuel_type',\n",
    "  'Genmodel_ID']\n",
    "\n",
    "\n",
    "\n",
    "categorical_df = data_df.loc[:,categorical_ids]\n",
    "\n",
    "continuous_df['Runned_Miles'] = pd.to_numeric(continuous_df['Runned_Miles'], errors='coerce')\n",
    "continuous_df['Price'] = pd.to_numeric(continuous_df['Price'], errors='coerce')\n",
    "\n",
    "# normalize\n",
    "continuous_df=(continuous_df-continuous_df.mean())/continuous_df.std()\n",
    "\n",
    "categorical_df['Color'] = categorical_df['Color'].astype('category')\n",
    "categorical_df['Bodytype'] = categorical_df['Bodytype'].astype('category')\n",
    "categorical_df['Gearbox'] = categorical_df['Gearbox'].astype('category')\n",
    "categorical_df['Fuel_type'] = categorical_df['Fuel_type'].astype('category')\n",
    "categorical_df['Genmodel_ID'] = categorical_df['Genmodel_ID'].astype('category')\n",
    "\n",
    "cat_columns = categorical_df.select_dtypes(['category']).columns\n",
    "\n",
    "categorical_df[cat_columns] = categorical_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data_df = pd.concat([id_df, continuous_df, categorical_df, image_name_df, viewpoint_df], axis=1)\n",
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_population = 100\n",
    "values = (data_df.value_counts(subset=['Genmodel_ID'])>=minimum_population).values\n",
    "codes = (data_df.value_counts(subset=['Genmodel_ID'])>=minimum_population).index\n",
    "populated_codes = []\n",
    "for i, v in enumerate(values):\n",
    "  if v:\n",
    "    populated_codes.append(int(codes[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(populated_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Price</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "      <th>Entry_price</th>\n",
       "      <th>Engine_size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Fuel_type</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Predicted_viewpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10_3$$1</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-1.311853</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.906021</td>\n",
       "      <td>6.323766</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Grey$$10_3$$1$$image_...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10_3$$3</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.830929</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.848026</td>\n",
       "      <td>6.594044</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Silver$$10_3$$3$$imag...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10_3$$10</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.815638</td>\n",
       "      <td>6.210746</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Blue$$10_3$$10$$image...</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10_3$$11</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-0.823261</td>\n",
       "      <td>6.108246</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$White$$10_3$$11$$imag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10_3$$12</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>-1.061788</td>\n",
       "      <td>7.133519</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>6.285820</td>\n",
       "      <td>5.331307</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bentley$$Bentayga$$2016$$Grey$$10_3$$12$$image...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209030</th>\n",
       "      <td>96_9$$353</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.145516</td>\n",
       "      <td>-0.581038</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209031</th>\n",
       "      <td>96_9$$374</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>2.282258</td>\n",
       "      <td>-0.610655</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.147646</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209032</th>\n",
       "      <td>96_9$$457</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.093532</td>\n",
       "      <td>-0.473358</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209033</th>\n",
       "      <td>96_9$$477</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-1.792777</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>2.357791</td>\n",
       "      <td>-0.608227</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>-0.111537</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209034</th>\n",
       "      <td>96_9$$525</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>-0.350005</td>\n",
       "      <td>-1.900760</td>\n",
       "      <td>1.393631</td>\n",
       "      <td>-0.532701</td>\n",
       "      <td>0.135216</td>\n",
       "      <td>0.61833</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>0.666012</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>285</td>\n",
       "      <td>Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176414 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Adv_ID  Adv_year  Adv_month  Reg_year  Runned_Miles     Price  \\\n",
       "28        10_3$$1  0.012811  -1.311853  0.876887     -0.906021  6.323766   \n",
       "29        10_3$$3  0.012811  -0.830929  0.876887     -0.848026  6.594044   \n",
       "31       10_3$$10  0.012811   0.130919  0.876887     -0.815638  6.210746   \n",
       "32       10_3$$11  0.012811   0.611842  0.876887     -0.823261  6.108246   \n",
       "33       10_3$$12  0.012811   0.130919  0.876887     -1.061788  7.133519   \n",
       "...           ...       ...        ...       ...           ...       ...   \n",
       "209030  96_9$$353  0.012811  -0.350005 -1.900760      1.145516 -0.581038   \n",
       "209031  96_9$$374  0.012811  -0.350005 -1.900760      2.282258 -0.610655   \n",
       "209032  96_9$$457  0.012811  -0.350005 -1.900760      1.093532 -0.473358   \n",
       "209033  96_9$$477  0.012811  -1.792777 -1.900760      2.357791 -0.608227   \n",
       "209034  96_9$$525  0.012811  -0.350005 -1.900760      1.393631 -0.532701   \n",
       "\n",
       "        Seat_num  Door_num  Entry_price  Engine_size  Color  Bodytype  \\\n",
       "28      0.135216   0.61833     6.285820     5.331307      8        10   \n",
       "29      0.135216   0.61833     6.285820     5.331307     18        10   \n",
       "31      0.135216   0.61833     6.285820     5.331307      2        10   \n",
       "32      0.135216   0.61833     6.285820     5.331307     20        10   \n",
       "33      0.135216   0.61833     6.285820     5.331307      8        10   \n",
       "...          ...       ...          ...          ...    ...       ...   \n",
       "209030  0.135216   0.61833    -0.204064     0.666012     18         4   \n",
       "209031  0.135216   0.61833    -0.204064     0.147646     18         4   \n",
       "209032  0.135216   0.61833    -0.204064     0.666012      8         4   \n",
       "209033  0.135216   0.61833    -0.204064    -0.111537      8         4   \n",
       "209034  0.135216   0.61833    -0.204064     0.666012     18         4   \n",
       "\n",
       "        Gearbox  Fuel_type  Genmodel_ID  \\\n",
       "28            0          8            0   \n",
       "29            0          8            0   \n",
       "31            0          8            0   \n",
       "32            0          8            0   \n",
       "33            0          8            0   \n",
       "...         ...        ...          ...   \n",
       "209030        0          8          285   \n",
       "209031        1          1          285   \n",
       "209032        0          8          285   \n",
       "209033        1          8          285   \n",
       "209034        0          8          285   \n",
       "\n",
       "                                               Image_name  Predicted_viewpoint  \n",
       "28      Bentley$$Bentayga$$2016$$Grey$$10_3$$1$$image_...                  225  \n",
       "29      Bentley$$Bentayga$$2016$$Silver$$10_3$$3$$imag...                  225  \n",
       "31      Bentley$$Bentayga$$2016$$Blue$$10_3$$10$$image...                  225  \n",
       "32      Bentley$$Bentayga$$2016$$White$$10_3$$11$$imag...                    0  \n",
       "33      Bentley$$Bentayga$$2016$$Grey$$10_3$$12$$image...                    0  \n",
       "...                                                   ...                  ...  \n",
       "209030   Volvo$$V50$$2004$$Silver$$96_9$$353$$image_0.jpg                   45  \n",
       "209031   Volvo$$V50$$2004$$Silver$$96_9$$374$$image_0.jpg                    0  \n",
       "209032     Volvo$$V50$$2004$$Grey$$96_9$$457$$image_0.jpg                   45  \n",
       "209033     Volvo$$V50$$2004$$Grey$$96_9$$477$$image_0.jpg                  315  \n",
       "209034   Volvo$$V50$$2004$$Silver$$96_9$$525$$image_0.jpg                  135  \n",
       "\n",
       "[176414 rows x 17 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df[data_df['Genmodel_ID'].isin(populated_codes)]\n",
    "map = {}\n",
    "for i,l in enumerate(data_df['Genmodel_ID'].unique()):\n",
    "  map[l] = i\n",
    "data_df['Genmodel_ID'] = data_df['Genmodel_ID'].map(map)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_indices = []\n",
    "for indx, row in data_df.iterrows():\n",
    "    im_name = row['Image_name']\n",
    "    split = im_name.split('$$')\n",
    "    path = join(BASE, 'resized_DVM', split[0], split[1], split[2], split[3], im_name)\n",
    "    if not os.path.exists(path):\n",
    "        bad_indices.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to features\\train_ids_all_views.pt\n",
      "Saving to features\\val_ids_all_views.pt\n",
      "Saving to features\\test_ids_all_views.pt\n",
      "Saving to features\\labels_model_all_train_all_views.pt\n",
      "Saving to features\\labels_model_all_val_all_views.pt\n",
      "Saving to features\\labels_model_all_test_all_views.pt\n",
      "Saving to features\\tabular_lengths_all_views.pt\n"
     ]
    }
   ],
   "source": [
    "_ids = list(data_df['Adv_ID'])\n",
    "addendum = '_all_views'\n",
    "non_feature_columns = ['Adv_ID', 'Image_name', 'Predicted_viewpoint', 'Genmodel_ID']\n",
    "if front_view_only:\n",
    "  train_set_ids, test_ids = train_test_split(_ids, test_size=0.1, random_state=2022)\n",
    "  train_ids, val_ids = train_test_split(train_set_ids, test_size=0.2, random_state=2022)\n",
    "  \n",
    "  bad_indices_train = torch.load(join(FEATURES, f'bad_indices_train{addendum}.pt'))\n",
    "  bad_indices_val = torch.load(join(FEATURES, f'bad_indices_val{addendum}.pt'))\n",
    "\n",
    "  print(f'Val length before {len(val_ids)}')\n",
    "  for _id in bad_indices_val:\n",
    "      val_ids.remove(_id)\n",
    "  print(f'Val length after {len(val_ids)}')\n",
    "\n",
    "  print(f'Train length before {len(train_ids)}')\n",
    "  for _id in bad_indices_train:\n",
    "      train_ids.remove(_id)\n",
    "  print(f'Train length after {len(train_ids)}')\n",
    "else:\n",
    "  addendum = '_all_views'\n",
    "  train_set_ids, test_ids = train_test_split(_ids, test_size=0.5, random_state=2022, stratify=data_df['Genmodel_ID'])\n",
    "  train_ids, val_ids = train_test_split(train_set_ids, test_size=0.2, random_state=2022, stratify=data_df[data_df['Adv_ID'].isin(train_set_ids)]['Genmodel_ID'])\n",
    "\n",
    "check_or_save(train_ids, join(FEATURES, f'train_ids{addendum}.pt'))\n",
    "check_or_save(val_ids, join(FEATURES, f'val_ids{addendum}.pt'))\n",
    "check_or_save(test_ids, join(FEATURES, f'test_ids{addendum}.pt'))\n",
    "\n",
    "train_df = data_df.set_index('Adv_ID').loc[train_ids]\n",
    "val_df = data_df.set_index('Adv_ID').loc[val_ids]\n",
    "test_df = data_df.set_index('Adv_ID').loc[test_ids]\n",
    "\n",
    "train_labels_all = list(train_df['Genmodel_ID'])\n",
    "val_labels_all = list(val_df['Genmodel_ID'])\n",
    "test_labels_all = list(test_df['Genmodel_ID'])\n",
    "\n",
    "check_or_save(train_labels_all, join(FEATURES,f'labels_model_all_train{addendum}.pt'))\n",
    "check_or_save(val_labels_all, join(FEATURES,f'labels_model_all_val{addendum}.pt'))\n",
    "check_or_save(test_labels_all, join(FEATURES,f'labels_model_all_test{addendum}.pt'))\n",
    "\n",
    "check_or_save(train_df.loc[:,~train_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_train_noOH{addendum}.csv'), index=False, header=False)\n",
    "check_or_save(val_df.loc[:,~val_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_val_noOH{addendum}.csv'), index=False, header=False)\n",
    "check_or_save(test_df.loc[:,~test_df.columns.isin(non_feature_columns)],join(FEATURES,f'dvm_features_test_noOH{addendum}.csv'), index=False, header=False)\n",
    "\n",
    "check_or_save(train_df, join(FEATURES,f'dvm_full_features_train_noOH{addendum}.csv'), index=True, header=True)\n",
    "check_or_save(val_df, join(FEATURES,f'dvm_full_features_val_noOH{addendum}.csv'), index=True, header=True)\n",
    "check_or_save(test_df, join(FEATURES,f'dvm_full_features_test_noOH{addendum}.csv'), index=True, header=True)\n",
    "\n",
    "lengths = [1 for i in range(len(continuous_df.columns))]\n",
    "\n",
    "if 'Genmodel_ID' in categorical_ids:\n",
    "  categorical_ids.remove('Genmodel_ID')\n",
    "max = list(data_df[categorical_ids].max(axis=0))\n",
    "max = [i+1 for i in max]\n",
    "lengths = lengths + max\n",
    "check_or_save(lengths, join(FEATURES, f'tabular_lengths{addendum}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to features\\train_paths_all_views.pt\n",
      "Saving to features\\val_paths_all_views.pt\n",
      "Saving to features\\test_paths_all_views.pt\n"
     ]
    }
   ],
   "source": [
    "def get_paths(df):\n",
    "  paths = []\n",
    "  for indx, row in df.iterrows():\n",
    "      im_name = row['Image_name']\n",
    "      split = im_name.split('$$')\n",
    "      path = join(BASE, 'resized_DVM', split[0], split[1], split[2], split[3], im_name)\n",
    "      paths.append(path)\n",
    "  return paths\n",
    "\n",
    "# For big dataset need to save only paths to load live\n",
    "addendum = '_all_views'\n",
    "train_df = pd.read_csv(join(FEATURES,f'dvm_full_features_train_noOH{addendum}.csv'))\n",
    "val_df = pd.read_csv(join(FEATURES,f'dvm_full_features_val_noOH{addendum}.csv'))\n",
    "test_df = pd.read_csv(join(FEATURES,f'dvm_full_features_test_noOH{addendum}.csv'))\n",
    "\n",
    "for df, name in zip([train_df, val_df, test_df], ['train', 'val', 'test']):\n",
    "  paths = get_paths(df)\n",
    "  check_or_save(paths, join(FEATURES, f'{name}_paths{addendum}.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Normalized Ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/70565 images\n",
      "Processed 2000/70565 images\n",
      "Processed 3000/70565 images\n",
      "Processed 4000/70565 images\n",
      "Processed 5000/70565 images\n",
      "Processed 6000/70565 images\n",
      "Processed 7000/70565 images\n",
      "Processed 8000/70565 images\n",
      "Processed 9000/70565 images\n",
      "Processed 10000/70565 images\n",
      "Processed 11000/70565 images\n",
      "Processed 12000/70565 images\n",
      "Processed 13000/70565 images\n",
      "Processed 14000/70565 images\n",
      "Processed 15000/70565 images\n",
      "Processed 16000/70565 images\n",
      "Processed 17000/70565 images\n",
      "Processed 18000/70565 images\n",
      "Processed 19000/70565 images\n",
      "Processed 20000/70565 images\n",
      "Processed 21000/70565 images\n",
      "Processed 22000/70565 images\n",
      "Processed 23000/70565 images\n",
      "Processed 24000/70565 images\n",
      "Processed 25000/70565 images\n",
      "Processed 26000/70565 images\n",
      "Processed 27000/70565 images\n",
      "Processed 28000/70565 images\n",
      "Processed 29000/70565 images\n",
      "Processed 30000/70565 images\n",
      "Processed 31000/70565 images\n",
      "Processed 32000/70565 images\n",
      "Processed 33000/70565 images\n",
      "Processed 34000/70565 images\n",
      "Processed 35000/70565 images\n",
      "Processed 36000/70565 images\n",
      "Processed 37000/70565 images\n",
      "Processed 38000/70565 images\n",
      "Processed 39000/70565 images\n",
      "Processed 40000/70565 images\n",
      "Processed 41000/70565 images\n",
      "Processed 42000/70565 images\n",
      "Processed 43000/70565 images\n",
      "Processed 44000/70565 images\n",
      "Processed 45000/70565 images\n",
      "Processed 46000/70565 images\n",
      "Processed 47000/70565 images\n",
      "Processed 48000/70565 images\n",
      "Processed 49000/70565 images\n",
      "Processed 50000/70565 images\n",
      "Processed 51000/70565 images\n",
      "Processed 52000/70565 images\n",
      "Processed 53000/70565 images\n",
      "Processed 54000/70565 images\n",
      "Processed 55000/70565 images\n",
      "Processed 56000/70565 images\n",
      "Processed 57000/70565 images\n",
      "Processed 58000/70565 images\n",
      "Processed 59000/70565 images\n",
      "Processed 60000/70565 images\n",
      "Processed 61000/70565 images\n",
      "Processed 62000/70565 images\n",
      "Processed 63000/70565 images\n",
      "Processed 64000/70565 images\n",
      "Processed 65000/70565 images\n",
      "Processed 66000/70565 images\n",
      "Processed 67000/70565 images\n",
      "Processed 68000/70565 images\n",
      "Processed 69000/70565 images\n",
      "Processed 70000/70565 images\n",
      "Processed 1000/17642 images\n",
      "Processed 2000/17642 images\n",
      "Processed 3000/17642 images\n",
      "Processed 4000/17642 images\n",
      "Processed 5000/17642 images\n",
      "Processed 6000/17642 images\n",
      "Processed 7000/17642 images\n",
      "Processed 8000/17642 images\n",
      "Processed 9000/17642 images\n",
      "Processed 10000/17642 images\n",
      "Processed 11000/17642 images\n",
      "Processed 12000/17642 images\n",
      "Processed 13000/17642 images\n",
      "Processed 14000/17642 images\n",
      "Processed 15000/17642 images\n",
      "Processed 16000/17642 images\n",
      "Processed 17000/17642 images\n",
      "Processed 1000/88207 images\n",
      "Processed 2000/88207 images\n",
      "Processed 3000/88207 images\n",
      "Processed 4000/88207 images\n",
      "Processed 5000/88207 images\n",
      "Processed 6000/88207 images\n",
      "Processed 7000/88207 images\n",
      "Processed 8000/88207 images\n",
      "Processed 9000/88207 images\n",
      "Processed 10000/88207 images\n",
      "Processed 11000/88207 images\n",
      "Processed 12000/88207 images\n",
      "Processed 13000/88207 images\n",
      "Processed 14000/88207 images\n",
      "Processed 15000/88207 images\n",
      "Processed 16000/88207 images\n",
      "Processed 17000/88207 images\n",
      "Processed 18000/88207 images\n",
      "Processed 19000/88207 images\n",
      "Processed 20000/88207 images\n",
      "Processed 21000/88207 images\n",
      "Processed 22000/88207 images\n",
      "Processed 23000/88207 images\n",
      "Processed 24000/88207 images\n",
      "Processed 25000/88207 images\n",
      "Processed 26000/88207 images\n",
      "Processed 27000/88207 images\n",
      "Processed 28000/88207 images\n",
      "Processed 29000/88207 images\n",
      "Processed 30000/88207 images\n",
      "Processed 31000/88207 images\n",
      "Processed 32000/88207 images\n",
      "Processed 33000/88207 images\n",
      "Processed 34000/88207 images\n",
      "Processed 35000/88207 images\n",
      "Processed 36000/88207 images\n",
      "Processed 37000/88207 images\n",
      "Processed 38000/88207 images\n",
      "Processed 39000/88207 images\n",
      "Processed 40000/88207 images\n",
      "Processed 41000/88207 images\n",
      "Processed 42000/88207 images\n",
      "Processed 43000/88207 images\n",
      "Processed 44000/88207 images\n",
      "Processed 45000/88207 images\n",
      "Processed 46000/88207 images\n",
      "Processed 47000/88207 images\n",
      "Processed 48000/88207 images\n",
      "Processed 49000/88207 images\n",
      "Processed 50000/88207 images\n",
      "Processed 51000/88207 images\n",
      "Processed 52000/88207 images\n",
      "Processed 53000/88207 images\n",
      "Processed 54000/88207 images\n",
      "Processed 55000/88207 images\n",
      "Processed 56000/88207 images\n",
      "Processed 57000/88207 images\n",
      "Processed 58000/88207 images\n",
      "Processed 59000/88207 images\n",
      "Processed 60000/88207 images\n",
      "Processed 61000/88207 images\n",
      "Processed 62000/88207 images\n",
      "Processed 63000/88207 images\n",
      "Processed 64000/88207 images\n",
      "Processed 65000/88207 images\n",
      "Processed 66000/88207 images\n",
      "Processed 67000/88207 images\n",
      "Processed 68000/88207 images\n",
      "Processed 69000/88207 images\n",
      "Processed 70000/88207 images\n",
      "Processed 71000/88207 images\n",
      "Processed 72000/88207 images\n",
      "Processed 73000/88207 images\n",
      "Processed 74000/88207 images\n",
      "Processed 75000/88207 images\n",
      "Processed 76000/88207 images\n",
      "Processed 77000/88207 images\n",
      "Processed 78000/88207 images\n",
      "Processed 79000/88207 images\n",
      "Processed 80000/88207 images\n",
      "Processed 81000/88207 images\n",
      "Processed 82000/88207 images\n",
      "Processed 83000/88207 images\n",
      "Processed 84000/88207 images\n",
      "Processed 85000/88207 images\n",
      "Processed 86000/88207 images\n",
      "Processed 87000/88207 images\n",
      "Processed 88000/88207 images\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "if front_view_only:\n",
    "  IMAGES = join(BASE, 'Confirmed_fronts')\n",
    "else:\n",
    "  IMAGES = join(BASE, 'resized_DVM')\n",
    "\n",
    "for df, t_split in zip([train_df, val_df, test_df], ['train', 'val', 'test']):\n",
    "    num_images = len(df)\n",
    "    \n",
    "    # Read one image to get the shape\n",
    "    sample_image_name = df.iloc[0]['Image_name']\n",
    "    split = sample_image_name.split('$$')\n",
    "    if front_view_only:\n",
    "        sample_path = join(IMAGES, split[0], split[2], sample_image_name)\n",
    "    else:\n",
    "        sample_path = join(IMAGES, split[0], split[1], split[2], split[3], sample_image_name)\n",
    "    sample_image = read_image(sample_path)\n",
    "    image_shape = sample_image.shape  # (channels, height, width)\n",
    "\n",
    "    # Open an HDF5 file to store the images\n",
    "    h5_file_path = join(FEATURES, f'{t_split}_images{addendum}.h5')\n",
    "    with h5py.File(h5_file_path, 'w') as h5f:\n",
    "        # Create a dataset to store all images\n",
    "        dset = h5f.create_dataset('images', shape=(num_images,) + image_shape, dtype='float32')\n",
    "        \n",
    "        for idx, row in enumerate(df.itertuples()):\n",
    "            image_name = row.Image_name\n",
    "            split = image_name.split('$$')\n",
    "            \n",
    "            if front_view_only:\n",
    "                path = join(IMAGES, split[0], split[2], image_name)\n",
    "            else:\n",
    "                path = join(IMAGES, split[0], split[1], split[2], split[3], image_name)\n",
    "            \n",
    "            image = read_image(path).float() / 255  # Normalize the image\n",
    "            dset[idx] = image.numpy()\n",
    "            \n",
    "            # Optionally, print progress\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f'Processed {idx + 1}/{num_images} images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Low Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_data_split(df, nclasses):\n",
    "  critical_ids = df.groupby('Genmodel_ID', as_index=False).head(n=1)['Adv_ID']\n",
    "  other_ids = df.loc[~df['Adv_ID'].isin(critical_ids)]['Adv_ID'].values\n",
    "  to_fill_size = (int(len(df)*0.1)-len(critical_ids))\n",
    "  stratify = None\n",
    "  if to_fill_size >= nclasses:\n",
    "    stratify = df.set_index('Adv_ID').loc[other_ids]['Genmodel_ID']\n",
    "  if to_fill_size > 0:\n",
    "    _, low_data_ids = train_test_split(other_ids, test_size=to_fill_size, random_state=2023, stratify=stratify)\n",
    "  else:\n",
    "    low_data_ids = []\n",
    "  new_ids = np.concatenate([critical_ids,low_data_ids])\n",
    "  return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to features\\train_ids_all_views_0.1.pt\n",
      "Saving to features\\labels_model_all_train_all_views_0.1.pt\n",
      "Saving to features\\train_ids_all_views_0.01.pt\n",
      "Saving to features\\labels_model_all_train_all_views_0.01.pt\n"
     ]
    }
   ],
   "source": [
    "addendum = '_all_views'\n",
    "data_str = 'images'\n",
    "location = \"\"\n",
    "non_feature_columns = ['Image_name', 'Genmodel_ID', 'Predicted_viewpoint', 'Adv_ID']\n",
    "nclasses = 151\n",
    "if addendum == '_all_views':\n",
    "    nclasses = 286\n",
    "\n",
    "for k, prev_k in zip([0.1, 0.01], ['', '_0.1']):\n",
    "    df = pd.read_csv(join(FEATURES, f'dvm_full_features_train_noOH{addendum}{prev_k}.csv'))\n",
    "    ids = torch.load(join(FEATURES, f'train_ids{addendum}{prev_k}.pt'))\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    h5_file_path = join(FEATURES, f'train_{data_str}{addendum}{location}{prev_k}.h5')\n",
    "    h5f = h5py.File(h5_file_path, 'r')\n",
    "    ims_dataset = h5f['images']  # Adjust the dataset name if different\n",
    "\n",
    "    labels = torch.load(join(FEATURES, f'labels_model_all_train{addendum}{prev_k}.pt'))\n",
    "\n",
    "    # Determine the low data IDs\n",
    "    low_data_ids = low_data_split(df, nclasses)\n",
    "\n",
    "    # Create a boolean mask for IDs in low_data_ids\n",
    "    true_false_mask = np.array([i in low_data_ids for i in ids])\n",
    "\n",
    "    # Filter the DataFrame and IDs\n",
    "    low_data_df = df.loc[true_false_mask]\n",
    "    low_data_ids = [id for id, keep in zip(ids, true_false_mask) if keep]\n",
    "\n",
    "    # Get indices of images to select\n",
    "    indices = np.where(true_false_mask)[0]\n",
    "\n",
    "    # Select images using the indices\n",
    "    low_data_ims = ims_dataset[indices]\n",
    "\n",
    "    # Select corresponding labels\n",
    "    low_data_labels = [labels[i] for i in indices]\n",
    "\n",
    "    # Save the data\n",
    "    check_or_save(low_data_df.loc[:, ~low_data_df.columns.isin(non_feature_columns)],\n",
    "                  join(FEATURES, f'dvm_features_train_noOH{addendum}_{k}.csv'),\n",
    "                  index=False, header=False)\n",
    "    check_or_save(low_data_df,\n",
    "                  join(FEATURES, f'dvm_full_features_train_noOH{addendum}_{k}.csv'),\n",
    "                  index=False, header=True)\n",
    "\n",
    "    # Save the selected images to a new HDF5 file or as needed\n",
    "    with h5py.File(join(FEATURES, f'train_{data_str}{addendum}{location}_{k}.h5'), 'w') as h5f_out:\n",
    "        h5f_out.create_dataset('images', data=low_data_ims)\n",
    "\n",
    "    check_or_save(low_data_ids, join(FEATURES, f'train_ids{addendum}_{k}.pt'))\n",
    "    check_or_save(low_data_labels, join(FEATURES, f'labels_model_all_train{addendum}_{k}.pt'))\n",
    "\n",
    "    # Close the HDF5 file\n",
    "    h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genmodel_ID\n",
      "257    192\n",
      "31     138\n",
      "40     107\n",
      "32     104\n",
      "261    103\n",
      "      ... \n",
      "158      5\n",
      "27       5\n",
      "21       5\n",
      "170      5\n",
      "0        5\n",
      "Length: 286, dtype: int64\n",
      "7056\n",
      "Genmodel_ID\n",
      "257    13\n",
      "31      9\n",
      "40      8\n",
      "181     7\n",
      "256     7\n",
      "       ..\n",
      "203     1\n",
      "246     1\n",
      "44      1\n",
      "251     1\n",
      "0       1\n",
      "Length: 286, dtype: int64\n",
      "705\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "for k in [0.1, 0.01]:\n",
    "  low_data_ids = torch.load(join(FEATURES, f'{split}_ids{addendum}_{k}.pt'))\n",
    "  low_data_df = pd.read_csv(join(FEATURES,f'dvm_full_features_{split}_noOH{addendum}_{k}.csv'))\n",
    "  print(low_data_df.value_counts('Genmodel_ID'))\n",
    "  print(len(low_data_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "from os.path import join\n",
    "\n",
    "BASE = ''\n",
    "TABLES = join(BASE, 'tables_V2.0')\n",
    "FEATURES = join(BASE, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape (C, H, W): (3, 300, 300)\n",
      "Transposed image shape (H, W, C): (300, 300, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the path to your HDF5 file\n",
    "h5_file_path = join(FEATURES, 'train_images_all_views.h5')\n",
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(h5_file_path, 'r') as h5f:\n",
    "    # Access the dataset containing the images\n",
    "    images_dataset = h5f['images']  # Adjust 'images' if your dataset name is different\n",
    "\n",
    "    img_size = 128\n",
    "\n",
    "    # Define your transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=29, sigma=(0.1, 2.0))\n",
    "        ], p=0.5),\n",
    "        transforms.RandomResizedCrop(\n",
    "            size=(img_size, img_size),\n",
    "            scale=(0.2, 1.0),\n",
    "            ratio=(0.75, 1.3333333333333333)\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Resize(size=(img_size, img_size)),\n",
    "        transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "        # Optionally, normalize the tensor\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                      std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Access an image by index\n",
    "    im_np = images_dataset[50]  # Replace '1' with any valid index\n",
    "    print(f\"Original image shape (C, H, W): {im_np.shape}\")  # (3, 300, 300)\n",
    "\n",
    "    # Transpose the NumPy array to (H, W, C)\n",
    "    im_np_transposed = np.transpose(im_np, (1, 2, 0))\n",
    "    print(f\"Transposed image shape (H, W, C): {im_np_transposed.shape}\")  # (300, 300, 3)\n",
    "\n",
    "    # Convert the NumPy array to a PIL image\n",
    "    im_pil = transforms.ToPILImage()(im_np_transposed.astype('uint8'))\n",
    "\n",
    "    # Apply the transformations\n",
    "    im_t = transform(im_pil)\n",
    "\n",
    "    # Convert the transformed image back to a NumPy array for plotting\n",
    "    im_t_np = im_t.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Since im_t is in [0,1], multiply by 255 to get pixel values in [0,255]\n",
    "    im_t_np = (im_t_np * 255).astype(np.uint8)\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(im_t_np)\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to your HDF5 file\n",
    "h5_file_path = join(FEATURES, 'train_images_all_views.h5')\n",
    "images_dataset = h5py.File(h5_file_path, 'r')['images']\n",
    "images_dataset[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Physical Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding missing values to physical table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill using other values\n",
    "physical_df_orig = pd.read_csv(join('tables_V2.0','Ad_table (extra).csv'))\n",
    "physical_df_orig.rename(columns={' Genmodel_ID':'Genmodel_ID', ' Genmodel':'Genmodel'}, inplace=True)\n",
    "\n",
    "# Manual touches\n",
    "\n",
    "# Peugeot RCZ\n",
    "physical_df_orig.loc[physical_df_orig['Genmodel_ID'] == '69_36','Wheelbase']=2612\n",
    "# Ford Grand C-Max\n",
    "physical_df_orig.loc[physical_df_orig['Genmodel_ID'] == '29_20','Wheelbase']=2788 \n",
    "\n",
    "def fill_from_other_entry(row):\n",
    "    for attr in ['Wheelbase', 'Length', 'Width', 'Height']:\n",
    "        if pd.isna(row[attr]) or row[attr]==0:\n",
    "            other_rows = physical_df_orig.loc[physical_df_orig['Genmodel_ID']==row['Genmodel_ID']]\n",
    "            other_rows.dropna(subset=[attr], inplace=True)\n",
    "            other_rows.drop_duplicates(subset=[attr], inplace=True)\n",
    "            other_rows = other_rows[other_rows[attr]>0]\n",
    "            if len(other_rows)>0:\n",
    "                row[attr] = other_rows[attr].values[0]\n",
    "    return row\n",
    "\n",
    "physical_df_orig = physical_df_orig.apply(fill_from_other_entry, axis=1)\n",
    "\n",
    "physical_df_orig.to_csv(join(FEATURES,'Ad_table_physical_filled.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add physical attributes to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jitter to physical dimensions so they aren't just labels\n",
    "def add_jitter(x, jitter=50):\n",
    "    return x + random.randint(-jitter, jitter)\n",
    "\n",
    "random.seed(2022)\n",
    "physical_df = pd.read_csv(join(FEATURES,'Ad_table_physical_filled.csv'))\n",
    "for attr in ['Wheelbase', 'Length', 'Width', 'Height']:\n",
    "    physical_df[attr] = physical_df[attr].apply(add_jitter)\n",
    "physical_df.to_csv(join(FEATURES,'Ad_table_physical_filled_jittered_50.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_48952\\2216702334.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  physical_only_df[attr] = (physical_only_df[attr]-physical_only_df[attr].mean())/physical_only_df[attr].std()\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_48952\\2216702334.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  physical_only_df[attr] = (physical_only_df[attr]-physical_only_df[attr].mean())/physical_only_df[attr].std()\n",
      "C:\\Users\\srira\\AppData\\Local\\Temp\\ipykernel_48952\\2216702334.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  physical_only_df[attr] = (physical_only_df[attr]-physical_only_df[attr].mean())/physical_only_df[attr].std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to features\\tabular_lengths_all_views_physical.pt\n",
      "Saving to features\\tabular_lengths_all_views_physical_only.pt\n"
     ]
    }
   ],
   "source": [
    "# Ford ranger (29_30) has wrong height. Missing 1 in front... 805.0 instead of 1805.0\n",
    "# Mercedes Benz (59_29) wrong wheelbase, 5246.0 instead of 3106\n",
    "# Kia Rio (43_9) wrong wheelbase, 4065.0 instead of 2580\n",
    "# FIXED\n",
    "\n",
    "\n",
    "physical_df = pd.read_csv(join(FEATURES,'Ad_table_physical_filled_jittered_50.csv'))[['Adv_ID', 'Wheelbase','Height','Width','Length']]\n",
    "for v in ['_all_views']:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        features_df = pd.read_csv(join(FEATURES,f'dvm_full_features_{split}_noOH{v}.csv'))\n",
    "        merged_df = features_df.merge(physical_df, on='Adv_ID')\n",
    "        physical_only_df = merged_df[['Wheelbase','Height','Width','Length','Bodytype']]\n",
    "\n",
    "        for attr in ['Wheelbase','Height','Width','Length']:\n",
    "            assert merged_df[attr].isna().sum()==0\n",
    "            assert (merged_df[attr]==0).sum()==0\n",
    "\n",
    "        # normalize physical attributes\n",
    "        for attr in ['Wheelbase','Height','Width','Length']:\n",
    "            merged_df[attr] = (merged_df[attr]-merged_df[attr].mean())/merged_df[attr].std()\n",
    "            physical_only_df[attr] = (physical_only_df[attr]-physical_only_df[attr].mean())/physical_only_df[attr].std()\n",
    "\n",
    "        # Drop unwanted cols\n",
    "        non_feature_columns = ['Adv_ID', 'Image_name', 'Genmodel_ID']\n",
    "        if v == '_all_views':\n",
    "            non_feature_columns.append('Predicted_viewpoint')\n",
    "        merged_df = merged_df.drop(non_feature_columns, axis=1)\n",
    "\n",
    "        merged_df_cols = merged_df.columns.tolist()\n",
    "        rearranged_cols = merged_df_cols[-4:]+merged_df_cols[:-4]\n",
    "        merged_df = merged_df[rearranged_cols]\n",
    "        check_or_save(merged_df, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50.csv'), index=False, header=False)\n",
    "        check_or_save(physical_only_df, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_only_jittered_50.csv'), index=False, header=False)\n",
    "    lengths = torch.load(join(FEATURES,f'tabular_lengths{v}.pt'))\n",
    "    new_lengths = [1,1,1,1]\n",
    "    lengths = new_lengths + lengths\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical.pt'))\n",
    "    lengths = [1,1,1,1,13]\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical_only.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Labels to Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to features\\tabular_lengths_all_views_physical_labeled.pt\n"
     ]
    }
   ],
   "source": [
    "for v in ['_all_views']:\n",
    "    for split in ['train', 'val']:\n",
    "        labels = torch.load(join(FEATURES,f'labels_model_all_{split}{v}.pt'))\n",
    "        features = pd.read_csv(join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50.csv'), header=None)\n",
    "        features['label'] = labels\n",
    "        check_or_save(features, join(FEATURES,f'dvm_features_{split}_noOH{v}_physical_jittered_50_labeled.csv'), index=False, header=False)\n",
    "    lengths = torch.load(join(FEATURES,f'tabular_lengths{v}_physical.pt'))\n",
    "    lengths.append(np.array(labels).max()+1)\n",
    "    check_or_save(lengths, join(FEATURES,f'tabular_lengths{v}_physical_labeled.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfsuper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
